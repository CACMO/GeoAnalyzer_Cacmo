{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMNYrwv3BFxMGbxW6p04z/Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CACMO/GeoAnalyzer_Cacmo/blob/main/Another_conversion_TESEC_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhn-EZXWWg4s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Cargar archivo CSV\n",
        "archivo_real = \"BZDT#115 Mainframe 815_(AGO.30.2024)DTA.CSV\"  # Simula el archivo dado\n",
        "# Read CSV, skipping 15 rows of metadata and using comma as separator\n",
        "raw_df = pd.read_csv(archivo_real, skiprows=15, sep=',')\n",
        "\n",
        "# Identify columns that represent individual tests (assuming they are purely numeric like '1', '2', '3')\n",
        "test_columns = [col for col in raw_df.columns if str(col).isdigit()]\n",
        "\n",
        "processed_data_list = []\n",
        "\n",
        "# Extract attribute rows based on the 'Test' column\n",
        "item_row = raw_df[raw_df['Test'] == 'Item'].iloc[0] if not raw_df[raw_df['Test'] == 'Item'].empty else pd.Series(dtype=object)\n",
        "limit_units_row = raw_df[raw_df['Test'] == 'Limit Units'].iloc[0] if not raw_df[raw_df['Test'] == 'Limit Units'].empty else pd.Series(dtype=object)\n",
        "bias1_value_row = raw_df[raw_df['Test'] == 'Bias 1 Value'].iloc[0] if not raw_df[raw_df['Test'] == 'Bias 1 Value'].empty else pd.Series(dtype=object)\n",
        "bias1_label_row = raw_df[raw_df['Test'] == 'Bias 1 Unit'].iloc[0] if not raw_df[raw_df['Test'] == 'Bias 1 Unit'].empty else pd.Series(dtype=object)\n",
        "\n",
        "# Check for 'Bin' row. If it exists, extract it. Otherwise, create a dummy one.\n",
        "bin_row_exists = raw_df['Test'].astype(str).str.contains('Bin', na=False).any()\n",
        "if bin_row_exists:\n",
        "    bin_row = raw_df[raw_df['Test'].astype(str).str.contains('Bin', na=False)].iloc[0]\n",
        "else:\n",
        "    bin_row = pd.Series(index=raw_df.columns, dtype=object)\n",
        "    for col in test_columns:\n",
        "        bin_row[col] = np.nan # Fill with NaN for other columns\n",
        "\n",
        "# Iterate through each test column (e.g., '1', '2', '3') to create structured data rows\n",
        "for col_name in test_columns:\n",
        "    test_dict = {\n",
        "        \"Test number\": int(col_name),\n",
        "        \"Item\": item_row.get(col_name, np.nan),\n",
        "        \"Bias 1 Label\": bias1_label_row.get(col_name, np.nan),\n",
        "        \"Bias 1\": pd.to_numeric(bias1_value_row.get(col_name, np.nan), errors='coerce'),\n",
        "        \"Units\": limit_units_row.get(col_name, np.nan),\n",
        "        \"Bin\": bin_row.get(col_name, np.nan)\n",
        "    }\n",
        "    processed_data_list.append(test_dict)\n",
        "\n",
        "# Convert the list of dictionaries into the main DataFrame 'data'\n",
        "data = pd.DataFrame(processed_data_list)\n",
        "\n",
        "# Filtrar los datos excluyendo etiquetas \"SAME\" del campo 'Item'\n",
        "data = data[~data['Item'].str.contains(\"SAME\", na=False)]\n",
        "\n",
        "# Configuración global - Crear el nombre para \"Test name\"\n",
        "data['Test name'] = data['Item'] + \"@\" + data['Bias 1 Label'].astype(str) + data['Units']\n",
        "\n",
        "# Definir límites (Hardcode aquí, deben procesarse según tabla real)\n",
        "limites_pruebas = {\n",
        "    \"Bias 1\": {\"low_limit\": 0.005, \"high_limit\": 0.020, \"name\": \"Bias@A\"},\n",
        "    \"Bias 2\": {\"low_limit\": 0.01, \"high_limit\": 0.015, \"name\": \"Bias@V\"}\n",
        "    # Agrega más límites y configuraciones si lo necesitas\n",
        "}\n",
        "\n",
        "# Generar resumen\n",
        "resultados_pruebas = []\n",
        "for index, row in data.iterrows():\n",
        "    bias_value = row[\"Bias 1\"]\n",
        "    bias_unit = row[\"Units\"]\n",
        "    bias_name = row[\"Test name\"]\n",
        "    low_limit = limites_pruebas[\"Bias 1\"][\"low_limit\"]\n",
        "    high_limit = limites_pruebas[\"Bias 1\"][\"high_limit\"]\n",
        "\n",
        "    # Estadísticas generales\n",
        "    if pd.api.types.is_number(bias_value):\n",
        "        mean_value = bias_value\n",
        "        stdev = 0 # Cannot calculate stdev for a single value\n",
        "        p50 = bias_value\n",
        "    elif pd.isnull(bias_value):\n",
        "        mean_value = 0\n",
        "        stdev = 0\n",
        "        p50 = 0\n",
        "    else: # Fallback for list-like bias_value, though not expected with current structure\n",
        "        mean_value = np.mean(bias_value)\n",
        "        stdev = np.std(bias_value)\n",
        "        p50 = np.percentile(bias_value, 50)\n",
        "\n",
        "    cp = (high_limit - low_limit) / (6 * stdev) if stdev != 0 else 0\n",
        "    cpk = min((high_limit - mean_value) / (3 * stdev), (mean_value - low_limit) / (3 * stdev)) if stdev != 0 else 0\n",
        "\n",
        "    # Resultados válidos y fallos\n",
        "    if pd.api.types.is_number(bias_value):\n",
        "        fail_count = 1 if (bias_value < low_limit) or (bias_value > high_limit) else 0\n",
        "        result_count = 1\n",
        "    elif pd.isnull(bias_value):\n",
        "        fail_count = 0\n",
        "        result_count = 0\n",
        "    else: # Fallback for list-like bias_value\n",
        "        fail_count = sum((bias_value < low_limit) | (bias_value > high_limit))\n",
        "        result_count = len(bias_value)\n",
        "\n",
        "    yield_percent = round(((result_count - fail_count) / result_count) * 100, 2) if result_count != 0 else 0\n",
        "\n",
        "    resultados_pruebas.append({\n",
        "        \"Test number\": row[\"Test number\"],\n",
        "        \"Test name\": bias_name,\n",
        "        \"Unit\": row[\"Units\"],\n",
        "        \"Soft Bin\": row[\"Bin\"],\n",
        "        \"Low limit\": low_limit,\n",
        "        \"High limit\": high_limit,\n",
        "        \"P50\": round(p50, 4),\n",
        "        \"Mean\": round(mean_value, 4),\n",
        "        \"Stdev\": round(stdev, 4),\n",
        "        \"Cp\": round(cp, 3),\n",
        "        \"Cpk\": round(cpk, 3),\n",
        "        \"Result count\": result_count,\n",
        "        \"Fail count\": fail_count,\n",
        "        \"Yield (%)\": yield_percent\n",
        "    })\n",
        "\n",
        "# Convertir resultados a DataFrame\n",
        "tabla_final = pd.DataFrame(resultados_pruebas)\n",
        "\n",
        "# Guardar tabla consolidada al CSV\n",
        "tabla_final.to_csv(\"Resultados_Modificados_ZDT_PGlobal.csv\", index=False)\n",
        "\n",
        "# Mostrar tabla final simulada\n",
        "print(tabla_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "910795c7"
      },
      "source": [
        "# Task\n",
        "Modify the code in cell `zhn-EZXWWg4s` to add detailed comments explaining each section, variable, and logical step. Rewrite the statistical calculations to group the processed data by 'Test name', 'Unit', 'Soft Bin', 'Low limit', and 'High limit', then calculate the mean, standard deviation (Stdev), P50, Cp, Cpk, Result count, Fail count, and Yield (%) for each group using the collected 'Bias 1' values. Finally, provide a summary of the changes and updated results to address the issue of zero statistical values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85670bb4"
      },
      "source": [
        "## Add Detailed Comments\n",
        "\n",
        "### Subtask:\n",
        "Add comprehensive comments to the existing code cell (`zhn-EZXWWg4s`) to explain each section, variable, and logical step in detail.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c9ce521"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires adding comprehensive comments to the existing code cell `zhn-EZXWWg4s`. I will regenerate the entire code block with detailed comments explaining the purpose of the script, major sections, variable declarations, and logical steps, as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8bc6a16"
      },
      "source": [
        "# This script processes raw test data from a CSV file, extracts key attributes, calculates statistical metrics for each test,\n",
        "# and consolidates the results into a final DataFrame for analysis and reporting.\n",
        "\n",
        "# --- Import Libraries ---\n",
        "# Import necessary libraries for data manipulation and numerical operations.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Load Data ---\n",
        "# Define the input CSV file name and load the data into a Pandas DataFrame.\n",
        "# The file is expected to contain metadata in the first 15 rows, which are skipped.\n",
        "# The separator is explicitly set to a comma.\n",
        "archivo_real = \"BZDT#115 Mainframe 815_(AGO.30.2024)DTA.CSV\"  # Specifies the name of the input CSV file containing raw test data.\n",
        "raw_df = pd.read_csv(archivo_real, skiprows=15, sep=',') # DataFrame holding the raw data read from the CSV, skipping initial metadata rows.\n",
        "\n",
        "# --- Identify Test Columns ---\n",
        "# Identifies columns that represent individual test numbers by checking if their names are purely numeric.\n",
        "# This ensures that only actual test data columns are considered for processing.\n",
        "test_columns = [col for col in raw_df.columns if str(col).isdigit()]\n",
        "\n",
        "# processed_data_list: An empty list to store dictionaries, each representing a processed test with its attributes and values.\n",
        "processed_data_list = []\n",
        "\n",
        "# --- Extract Attribute Rows ---\n",
        "# These lines extract specific rows from the raw_df that contain meta-information for each test.\n",
        "# They are identified by unique values in the 'Test' column (e.g., 'Item', 'Limit Units').\n",
        "# .iloc[0] is used to get the first (and expected only) matching row.\n",
        "# If a row is not found, an empty Series is created to prevent errors.\n",
        "item_row = raw_df[raw_df['Test'] == 'Item'].iloc[0] if not raw_df[raw_df['Test'] == 'Item'].empty else pd.Series(dtype=object) # Series containing 'Item' labels for each test.\n",
        "limit_units_row = raw_df[raw_df['Test'] == 'Limit Units'].iloc[0] if not raw_df[raw_df['Test'] == 'Limit Units'].empty else pd.Series(dtype=object) # Series containing 'Limit Units' for each test.\n",
        "bias1_value_row = raw_df[raw_df['Test'] == 'Bias 1 Value'].iloc[0] if not raw_df[raw_df['Test'] == 'Bias 1 Value'].empty else pd.Series(dtype=object) # Series containing 'Bias 1 Value' for each test.\n",
        "bias1_label_row = raw_df[raw_df['Test'] == 'Bias 1 Unit'].iloc[0] if not raw_df[raw_df['Test'] == 'Bias 1 Unit'].empty else pd.Series(dtype=object) # Series containing 'Bias 1 Unit' labels for each test.\n",
        "\n",
        "# Check for 'Bin' row. If it exists, extract it. Otherwise, create a dummy one.\n",
        "# The 'Bin' row indicates classification bins for tests, if available.\n",
        "bin_row_exists = raw_df['Test'].astype(str).str.contains('Bin', na=False).any() # Boolean flag indicating if a 'Bin' row exists in the raw data.\n",
        "if bin_row_exists:\n",
        "    bin_row = raw_df[raw_df['Test'].astype(str).str.contains('Bin', na=False)].iloc[0] # Series containing 'Bin' information for each test, if present.\n",
        "else:\n",
        "    bin_row = pd.Series(index=raw_df.columns, dtype=object) # Dummy Series created if no 'Bin' row is found.\n",
        "    for col in test_columns:\n",
        "        bin_row[col] = np.nan # Fills 'Bin' values with NaN for each test column if no 'Bin' row exists.\n",
        "\n",
        "# --- Process Test Data ---\n",
        "# Iterates through each identified test column to consolidate its attributes into a dictionary.\n",
        "# Each dictionary is then appended to `processed_data_list`.\n",
        "for col_name in test_columns:\n",
        "    # test_dict: A dictionary to hold attributes for the current test number.\n",
        "    test_dict = {\n",
        "        \"Test number\": int(col_name), # The numerical identifier for the test.\n",
        "        \"Item\": item_row.get(col_name, np.nan), # The 'Item' (name) of the test.\n",
        "        \"Bias 1 Label\": bias1_label_row.get(col_name, np.nan), # The label associated with 'Bias 1' (e.g., 'VSG').\n",
        "        \"Bias 1\": pd.to_numeric(bias1_value_row.get(col_name, np.nan), errors='coerce'), # The numerical value of 'Bias 1', converted to numeric.\n",
        "        \"Units\": limit_units_row.get(col_name, np.nan), # The units for the test limits.\n",
        "        \"Bin\": bin_row.get(col_name, np.nan) # The bin classification for the test.\n",
        "    }\n",
        "    processed_data_list.append(test_dict)\n",
        "\n",
        "# Convert the list of dictionaries into the main DataFrame 'data'.\n",
        "data = pd.DataFrame(processed_data_list) # DataFrame created from the processed test dictionaries.\n",
        "\n",
        "# --- Filter and Prepare Data ---\n",
        "# Filters out rows where the 'Item' column contains the string \"SAME\".\n",
        "# These rows typically represent duplicate or skipped tests and are not needed for final analysis.\n",
        "data = data[~data['Item'].str.contains(\"SAME\", na=False)] # Filters out tests marked as 'SAME'.\n",
        "\n",
        "# Creates a new column 'Test name' by concatenating 'Item', 'Bias 1 Label', and 'Units'.\n",
        "# This provides a more descriptive name for each test.\n",
        "data['Test name'] = data['Item'] + \"@\" + data['Bias 1 Label'].astype(str) + data['Units'] # A descriptive name for each test, combining item, bias label, and units.\n",
        "\n",
        "# --- Define Limits ---\n",
        "# Hardcoded limits for different bias types. In a real scenario, these would likely be loaded from a configuration file or database.\n",
        "# limites_pruebas: A dictionary defining the low and high limits for various bias tests, along with a descriptive name.\n",
        "limites_pruebas = {\n",
        "    \"Bias 1\": {\"low_limit\": 0.005, \"high_limit\": 0.020, \"name\": \"Bias@A\"},\n",
        "    \"Bias 2\": {\"low_limit\": 0.01, \"high_limit\": 0.015, \"name\": \"Bias@V\"}\n",
        "    # Add more limits and configurations if needed\n",
        "}\n",
        "\n",
        "# --- Calculate Statistics for Each Test ---\n",
        "# resultados_pruebas: An empty list to store dictionaries, each containing calculated statistics for a test.\n",
        "resultados_pruebas = []\n",
        "\n",
        "# Iterates through each row (test) in the 'data' DataFrame to calculate statistical metrics.\n",
        "for index, row in data.iterrows():\n",
        "    bias_value = row[\"Bias 1\"] # The measured 'Bias 1' value for the current test.\n",
        "    bias_unit = row[\"Units\"] # The unit of the 'Bias 1' value.\n",
        "    bias_name = row[\"Test name\"] # The descriptive name of the test.\n",
        "    low_limit = limites_pruebas[\"Bias 1\"][\"low_limit\"] # The lower limit for 'Bias 1' from the defined limits.\n",
        "    high_limit = limites_pruebas[\"Bias 1\"][\"high_limit\"] # The upper limit for 'Bias 1' from the defined limits.\n",
        "\n",
        "    # --- General Statistics Calculation ---\n",
        "    # Calculates mean, standard deviation, and P50 (median) for the bias value.\n",
        "    # Handles cases where bias_value might be a single number, NaN, or (hypothetically) a list.\n",
        "    if pd.api.types.is_number(bias_value): # Check if bias_value is a single numeric value.\n",
        "        mean_value = bias_value # Mean is the value itself for a single point.\n",
        "        stdev = 0 # Standard deviation is 0 for a single data point.\n",
        "        p50 = bias_value # P50 (median) is the value itself for a single point.\n",
        "    elif pd.isnull(bias_value): # Check if bias_value is NaN.\n",
        "        mean_value = 0 # Default mean to 0 if value is missing.\n",
        "        stdev = 0 # Default stdev to 0 if value is missing.\n",
        "        p50 = 0 # Default P50 to 0 if value is missing.\n",
        "    else: # Fallback for list-like bias_value, though not expected with current structure.\n",
        "        mean_value = np.mean(bias_value)\n",
        "        stdev = np.std(bias_value)\n",
        "        p50 = np.percentile(bias_value, 50)\n",
        "\n",
        "    # Cp (Process Capability Index): Measures if a process is capable of meeting specifications.\n",
        "    # Calculated as (Upper Spec Limit - Lower Spec Limit) / (6 * Standard Deviation).\n",
        "    # If stdev is 0, Cp is 0 to avoid division by zero.\n",
        "    cp = (high_limit - low_limit) / (6 * stdev) if stdev != 0 else 0\n",
        "\n",
        "    # Cpk (Process Capability Index, minimum of two sides): Measures how close the process mean is to the specification limits.\n",
        "    # Calculated as the minimum of (USL - Mean) / (3 * Stdev) and (Mean - LSL) / (3 * Stdev).\n",
        "    # If stdev is 0, Cpk is 0 to avoid division by zero.\n",
        "    cpk = min((high_limit - mean_value) / (3 * stdev), (mean_value - low_limit) / (3 * stdev)) if stdev != 0 else 0\n",
        "\n",
        "    # --- Valid Results and Failures Calculation ---\n",
        "    # Determines the count of valid results and failures based on the defined limits.\n",
        "    if pd.api.types.is_number(bias_value): # If bias_value is a single numeric value.\n",
        "        fail_count = 1 if (bias_value < low_limit) or (bias_value > high_limit) else 0 # Counts as a failure if value is outside limits.\n",
        "        result_count = 1 # There is 1 result for a single data point.\n",
        "    elif pd.isnull(bias_value): # If bias_value is NaN.\n",
        "        fail_count = 0 # No failures if no value.\n",
        "        result_count = 0 # No results if no value.\n",
        "    else: # Fallback for list-like bias_value.\n",
        "        fail_count = sum((bias_value < low_limit) | (bias_value > high_limit))\n",
        "        result_count = len(bias_value)\n",
        "\n",
        "    # Yield (%): The percentage of results that fall within the specified limits.\n",
        "    # Calculated as ((Total Results - Failures) / Total Results) * 100.\n",
        "    # If result_count is 0, yield is 0 to avoid division by zero.\n",
        "    yield_percent = round(((result_count - fail_count) / result_count) * 100, 2) if result_count != 0 else 0\n",
        "\n",
        "    # Appends the calculated statistics for the current test to the list.\n",
        "    resultados_pruebas.append({\n",
        "        \"Test number\": row[\"Test number\"],\n",
        "        \"Test name\": bias_name,\n",
        "        \"Unit\": row[\"Units\"],\n",
        "        \"Soft Bin\": row[\"Bin\"],\n",
        "        \"Low limit\": low_limit,\n",
        "        \"High limit\": high_limit,\n",
        "        \"P50\": round(p50, 4),\n",
        "        \"Mean\": round(mean_value, 4),\n",
        "        \"Stdev\": round(stdev, 4),\n",
        "        \"Cp\": round(cp, 3),\n",
        "        \"Cpk\": round(cpk, 3),\n",
        "        \"Result count\": result_count,\n",
        "        \"Fail count\": fail_count,\n",
        "        \"Yield (%)\": yield_percent\n",
        "    })\n",
        "\n",
        "# --- Final Output ---\n",
        "# Converts the list of statistical results into a final DataFrame.\n",
        "tabla_final = pd.DataFrame(resultados_pruebas) # Final DataFrame containing all calculated statistics for each relevant test.\n",
        "\n",
        "# Saves the final consolidated table to a CSV file without the DataFrame index.\n",
        "tabla_final.to_csv(\"Resultados_Modificados_ZDT_PGlobal.csv\", index=False)\n",
        "\n",
        "# Prints the final DataFrame to the console for review.\n",
        "print(tabla_final)\n",
        "```\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf200a11"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block contained an extraneous ` (backtick) character at the end, which caused a `SyntaxError`. I need to remove this character to fix the syntax error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "931905e5"
      },
      "source": [
        "# This script processes raw test data from a CSV file, extracts key attributes, calculates statistical metrics for each test,\n",
        "# and consolidates the results into a final DataFrame for analysis and reporting.\n",
        "\n",
        "# --- Import Libraries ---\n",
        "# Import necessary libraries for data manipulation and numerical operations.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Load Data ---\n",
        "# Define the input CSV file name and load the data into a Pandas DataFrame.\n",
        "# The file is expected to contain metadata in the first 15 rows, which are skipped.\n",
        "# The separator is explicitly set to a comma.\n",
        "archivo_real = \"BZDT#115 Mainframe 815_(AGO.30.2024)DTA.CSV\"  # Specifies the name of the input CSV file containing raw test data.\n",
        "raw_df = pd.read_csv(archivo_real, skiprows=15, sep=',') # DataFrame holding the raw data read from the CSV, skipping initial metadata rows.\n",
        "\n",
        "# --- Identify Test Columns ---\n",
        "# Identifies columns that represent individual test numbers by checking if their names are purely numeric.\n",
        "# This ensures that only actual test data columns are considered for processing.\n",
        "test_columns = [col for col in raw_df.columns if str(col).isdigit()]\n",
        "\n",
        "# processed_data_list: An empty list to store dictionaries, each representing a processed test with its attributes and values.\n",
        "processed_data_list = []\n",
        "\n",
        "# --- Extract Attribute Rows ---\n",
        "# These lines extract specific rows from the raw_df that contain meta-information for each test.\n",
        "# They are identified by unique values in the 'Test' column (e.g., 'Item', 'Limit Units').\n",
        "# .iloc[0] is used to get the first (and expected only) matching row.\n",
        "# If a row is not found, an empty Series is created to prevent errors.\n",
        "item_row = raw_df[raw_df['Test'] == 'Item'].iloc[0] if not raw_df[raw_df['Test'] == 'Item'].empty else pd.Series(dtype=object) # Series containing 'Item' labels for each test.\n",
        "limit_units_row = raw_df[raw_df['Test'] == 'Limit Units'].iloc[0] if not raw_df[raw_df['Test'] == 'Limit Units'].empty else pd.Series(dtype=object) # Series containing 'Limit Units' for each test.\n",
        "bias1_value_row = raw_df[raw_df['Test'] == 'Bias 1 Value'].iloc[0] if not raw_df[raw_df['Test'] == 'Bias 1 Value'].empty else pd.Series(dtype=object) # Series containing 'Bias 1 Value' for each test.\n",
        "bias1_label_row = raw_df[raw_df['Test'] == 'Bias 1 Unit'].iloc[0] if not raw_df[raw_df['Test'] == 'Bias 1 Unit'].empty else pd.Series(dtype=object) # Series containing 'Bias 1 Unit' labels for each test.\n",
        "\n",
        "# Check for 'Bin' row. If it exists, extract it. Otherwise, create a dummy one.\n",
        "# The 'Bin' row indicates classification bins for tests, if available.\n",
        "bin_row_exists = raw_df['Test'].astype(str).str.contains('Bin', na=False).any() # Boolean flag indicating if a 'Bin' row exists in the raw data.\n",
        "if bin_row_exists:\n",
        "    bin_row = raw_df[raw_df['Test'].astype(str).str.contains('Bin', na=False)].iloc[0] # Series containing 'Bin' information for each test, if present.\n",
        "else:\n",
        "    bin_row = pd.Series(index=raw_df.columns, dtype=object) # Dummy Series created if no 'Bin' row is found.\n",
        "    for col in test_columns:\n",
        "        bin_row[col] = np.nan # Fills 'Bin' values with NaN for each test column if no 'Bin' row exists.\n",
        "\n",
        "# --- Process Test Data ---\n",
        "# Iterates through each identified test column to consolidate its attributes into a dictionary.\n",
        "# Each dictionary is then appended to `processed_data_list`.\n",
        "for col_name in test_columns:\n",
        "    # test_dict: A dictionary to hold attributes for the current test number.\n",
        "    test_dict = {\n",
        "        \"Test number\": int(col_name), # The numerical identifier for the test.\n",
        "        \"Item\": item_row.get(col_name, np.nan), # The 'Item' (name) of the test.\n",
        "        \"Bias 1 Label\": bias1_label_row.get(col_name, np.nan), # The label associated with 'Bias 1' (e.g., 'VSG').\n",
        "        \"Bias 1\": pd.to_numeric(bias1_value_row.get(col_name, np.nan), errors='coerce'), # The numerical value of 'Bias 1', converted to numeric.\n",
        "        \"Units\": limit_units_row.get(col_name, np.nan), # The units for the test limits.\n",
        "        \"Bin\": bin_row.get(col_name, np.nan) # The bin classification for the test.\n",
        "    }\n",
        "    processed_data_list.append(test_dict)\n",
        "\n",
        "# Convert the list of dictionaries into the main DataFrame 'data'.\n",
        "data = pd.DataFrame(processed_data_list) # DataFrame created from the processed test dictionaries.\n",
        "\n",
        "# --- Filter and Prepare Data ---\n",
        "# Filters out rows where the 'Item' column contains the string \"SAME\".\n",
        "# These rows typically represent duplicate or skipped tests and are not needed for final analysis.\n",
        "data = data[~data['Item'].str.contains(\"SAME\", na=False)] # Filters out tests marked as 'SAME'.\n",
        "\n",
        "# Creates a new column 'Test name' by concatenating 'Item', 'Bias 1 Label', and 'Units'.\n",
        "# This provides a more descriptive name for each test.\n",
        "data['Test name'] = data['Item'] + \"@\" + data['Bias 1 Label'].astype(str) + data['Units'] # A descriptive name for each test, combining item, bias label, and units.\n",
        "\n",
        "# --- Define Limits ---\n",
        "# Hardcoded limits for different bias types. In a real scenario, these would likely be loaded from a configuration file or database.\n",
        "# limites_pruebas: A dictionary defining the low and high limits for various bias tests, along with a descriptive name.\n",
        "limites_pruebas = {\n",
        "    \"Bias 1\": {\"low_limit\": 0.005, \"high_limit\": 0.020, \"name\": \"Bias@A\"},\n",
        "    \"Bias 2\": {\"low_limit\": 0.01, \"high_limit\": 0.015, \"name\": \"Bias@V\"}\n",
        "    # Add more limits and configurations if needed\n",
        "}\n",
        "\n",
        "# --- Calculate Statistics for Each Test ---\n",
        "# resultados_pruebas: An empty list to store dictionaries, each containing calculated statistics for a test.\n",
        "resultados_pruebas = []\n",
        "\n",
        "# Iterates through each row (test) in the 'data' DataFrame to calculate statistical metrics.\n",
        "for index, row in data.iterrows():\n",
        "    bias_value = row[\"Bias 1\"] # The measured 'Bias 1' value for the current test.\n",
        "    bias_unit = row[\"Units\"] # The unit of the 'Bias 1' value.\n",
        "    bias_name = row[\"Test name\"] # The descriptive name of the test.\n",
        "    low_limit = limites_pruebas[\"Bias 1\"][\"low_limit\"] # The lower limit for 'Bias 1' from the defined limits.\n",
        "    high_limit = limites_pruebas[\"Bias 1\"][\"high_limit\"] # The upper limit for 'Bias 1' from the defined limits.\n",
        "\n",
        "    # --- General Statistics Calculation ---\n",
        "    # Calculates mean, standard deviation, and P50 (median) for the bias value.\n",
        "    # Handles cases where bias_value might be a single number, NaN, or (hypothetically) a list.\n",
        "    if pd.api.types.is_number(bias_value): # Check if bias_value is a single numeric value.\n",
        "        mean_value = bias_value # Mean is the value itself for a single point.\n",
        "        stdev = 0 # Standard deviation is 0 for a single data point.\n",
        "        p50 = bias_value # P50 (median) is the value itself for a single point.\n",
        "    elif pd.isnull(bias_value): # Check if bias_value is NaN.\n",
        "        mean_value = 0 # Default mean to 0 if value is missing.\n",
        "        stdev = 0 # Default stdev to 0 if value is missing.\n",
        "        p50 = 0 # Default P50 to 0 if value is missing.\n",
        "    else: # Fallback for list-like bias_value, though not expected with current structure.\n",
        "        mean_value = np.mean(bias_value)\n",
        "        stdev = np.std(bias_value)\n",
        "        p50 = np.percentile(bias_value, 50)\n",
        "\n",
        "    # Cp (Process Capability Index): Measures if a process is capable of meeting specifications.\n",
        "    # Calculated as (Upper Spec Limit - Lower Spec Limit) / (6 * Standard Deviation).\n",
        "    # If stdev is 0, Cp is 0 to avoid division by zero.\n",
        "    cp = (high_limit - low_limit) / (6 * stdev) if stdev != 0 else 0\n",
        "\n",
        "    # Cpk (Process Capability Index, minimum of two sides): Measures how close the process mean is to the specification limits.\n",
        "    # Calculated as the minimum of (USL - Mean) / (3 * Stdev) and (Mean - LSL) / (3 * Stdev).\n",
        "    # If stdev is 0, Cpk is 0 to avoid division by zero.\n",
        "    cpk = min((high_limit - mean_value) / (3 * stdev), (mean_value - low_limit) / (3 * stdev)) if stdev != 0 else 0\n",
        "\n",
        "    # --- Valid Results and Failures Calculation ---\n",
        "    # Determines the count of valid results and failures based on the defined limits.\n",
        "    if pd.api.types.is_number(bias_value): # If bias_value is a single numeric value.\n",
        "        fail_count = 1 if (bias_value < low_limit) or (bias_value > high_limit) else 0 # Counts as a failure if value is outside limits.\n",
        "        result_count = 1 # There is 1 result for a single data point.\n",
        "    elif pd.isnull(bias_value): # If bias_value is NaN.\n",
        "        fail_count = 0 # No failures if no value.\n",
        "        result_count = 0 # No results if no value.\n",
        "    else: # Fallback for list-like bias_value.\n",
        "        fail_count = sum((bias_value < low_limit) | (bias_value > high_limit))\n",
        "        result_count = len(bias_value)\n",
        "\n",
        "    # Yield (%): The percentage of results that fall within the specified limits.\n",
        "    # Calculated as ((Total Results - Failures) / Total Results) * 100.\n",
        "    # If result_count is 0, yield is 0 to avoid division by zero.\n",
        "    yield_percent = round(((result_count - fail_count) / result_count) * 100, 2) if result_count != 0 else 0\n",
        "\n",
        "    # Appends the calculated statistics for the current test to the list.\n",
        "    resultados_pruebas.append({\n",
        "        \"Test number\": row[\"Test number\"],\n",
        "        \"Test name\": bias_name,\n",
        "        \"Unit\": row[\"Units\"],\n",
        "        \"Soft Bin\": row[\"Bin\"],\n",
        "        \"Low limit\": low_limit,\n",
        "        \"High limit\": high_limit,\n",
        "        \"P50\": round(p50, 4),\n",
        "        \"Mean\": round(mean_value, 4),\n",
        "        \"Stdev\": round(stdev, 4),\n",
        "        \"Cp\": round(cp, 3),\n",
        "        \"Cpk\": round(cpk, 3),\n",
        "        \"Result count\": result_count,\n",
        "        \"Fail count\": fail_count,\n",
        "        \"Yield (%)\": yield_percent\n",
        "    })\n",
        "\n",
        "# --- Final Output ---\n",
        "# Converts the list of statistical results into a final DataFrame.\n",
        "tabla_final = pd.DataFrame(resultados_pruebas) # Final DataFrame containing all calculated statistics for each relevant test.\n",
        "\n",
        "# Saves the final consolidated table to a CSV file without the DataFrame index.\n",
        "tabla_final.to_csv(\"Resultados_Modificados_ZDT_PGlobal.csv\", index=False)\n",
        "\n",
        "# Prints the final DataFrame to the console for review.\n",
        "print(tabla_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3408e54e"
      },
      "source": [
        "## Rewrite Statistical Calculations\n",
        "\n",
        "### Subtask:\n",
        "Modify the code to group the processed data by 'Test name', 'Unit', 'Soft Bin', 'Low limit', and 'High limit', then calculate the mean, standard deviation (Stdev), P50, Cp, Cpk, Result count, Fail count, and Yield (%) for each group using the collected 'Bias 1' values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4f02493"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the statistical calculation logic. I will define a new function `calculate_group_stats` to compute the required metrics for a group of 'Bias 1' values. Then, I will replace the existing row-wise iteration with a grouping operation using `groupby()` and `apply()` to aggregate statistics per defined group. The `tabla_final` DataFrame will be reconstructed from these grouped statistics. The `limites_pruebas` dictionary is already defined, and its values will be used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "691bc179"
      },
      "source": [
        "# This script processes raw test data from a CSV file, extracts key attributes, calculates statistical metrics for each test,\n",
        "# and consolidates the results into a final DataFrame for analysis and reporting.\n",
        "\n",
        "# --- Import Libraries ---\n",
        "# Import necessary libraries for data manipulation and numerical operations.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Load Data ---\n",
        "# Define the input CSV file name and load the data into a Pandas DataFrame.\n",
        "# The file is expected to contain metadata in the first 15 rows, which are skipped.\n",
        "# The separator is explicitly set to a comma.\n",
        "archivo_real = \"BZDT#115 Mainframe 815_(AGO.30.2024)DTA.CSV\"  # Specifies the name of the input CSV file containing raw test data.\n",
        "raw_df = pd.read_csv(archivo_real, skiprows=15, sep=',') # DataFrame holding the raw data read from the CSV, skipping initial metadata rows.\n",
        "\n",
        "# --- Identify Test Columns ---\n",
        "# Identifies columns that represent individual test numbers by checking if their names are purely numeric.\n",
        "# This ensures that only actual test data columns are considered for processing.\n",
        "test_columns = [col for col in raw_df.columns if str(col).isdigit()]\n",
        "\n",
        "# processed_data_list: An empty list to store dictionaries, each representing a processed test with its attributes and values.\n",
        "processed_data_list = []\n",
        "\n",
        "# --- Extract Attribute Rows ---\n",
        "# These lines extract specific rows from the raw_df that contain meta-information for each test.\n",
        "# They are identified by unique values in the 'Test' column (e.g., 'Item', 'Limit Units').\n",
        "# .iloc[0] is used to get the first (and expected only) matching row.\n",
        "# If a row is not found, an empty Series is created to prevent errors.\n",
        "item_row = raw_df[raw_df['Test'] == 'Item'].iloc[0] if not raw_df[raw_df['Test'] == 'Item'].empty else pd.Series(dtype=object) # Series containing 'Item' labels for each test.\n",
        "limit_units_row = raw_df[raw_df['Test'] == 'Limit Units'].iloc[0] if not raw_df[raw_df['Test'] == 'Limit Units'].empty else pd.Series(dtype=object) # Series containing 'Limit Units' for each test.\n",
        "bias1_value_row = raw_df[raw_df['Test'] == 'Bias 1 Value'].iloc[0] if not raw_df[raw_df['Test'] == 'Bias 1 Value'].empty else pd.Series(dtype=object) # Series containing 'Bias 1 Value' for each test.\n",
        "bias1_label_row = raw_df[raw_df['Test'] == 'Bias 1 Unit'].iloc[0] if not raw_df[raw_df['Test'] == 'Bias 1 Unit'].empty else pd.Series(dtype=object) # Series containing 'Bias 1 Unit' labels for each test.\n",
        "\n",
        "# Check for 'Bin' row. If it exists, extract it. Otherwise, create a dummy one.\n",
        "# The 'Bin' row indicates classification bins for tests, if available.\n",
        "bin_row_exists = raw_df['Test'].astype(str).str.contains('Bin', na=False).any() # Boolean flag indicating if a 'Bin' row exists in the raw data.\n",
        "if bin_row_exists:\n",
        "    bin_row = raw_df[raw_df['Test'].astype(str).str.contains('Bin', na=False)].iloc[0] # Series containing 'Bin' information for each test, if present.\n",
        "else:\n",
        "    bin_row = pd.Series(index=raw_df.columns, dtype=object) # Dummy Series created if no 'Bin' row is found.\n",
        "    for col in test_columns:\n",
        "        bin_row[col] = np.nan # Fills 'Bin' values with NaN for each test column if no 'Bin' row exists.\n",
        "\n",
        "# --- Process Test Data ---\n",
        "# Iterates through each identified test column to consolidate its attributes into a dictionary.\n",
        "# Each dictionary is then appended to `processed_data_list`.\n",
        "for col_name in test_columns:\n",
        "    # test_dict: A dictionary to hold attributes for the current test number.\n",
        "    test_dict = {\n",
        "        \"Test number\": int(col_name), # The numerical identifier for the test.\n",
        "        \"Item\": item_row.get(col_name, np.nan), # The 'Item' (name) of the test.\n",
        "        \"Bias 1 Label\": bias1_label_row.get(col_name, np.nan), # The label associated with 'Bias 1' (e.g., 'VSG').\n",
        "        \"Bias 1\": pd.to_numeric(bias1_value_row.get(col_name, np.nan), errors='coerce'), # The numerical value of 'Bias 1', converted to numeric.\n",
        "        \"Units\": limit_units_row.get(col_name, np.nan), # The units for the test limits.\n",
        "        \"Bin\": bin_row.get(col_name, np.nan) # The bin classification for the test.\n",
        "    }\n",
        "    processed_data_list.append(test_dict)\n",
        "\n",
        "# Convert the list of dictionaries into the main DataFrame 'data'.\n",
        "data = pd.DataFrame(processed_data_list) # DataFrame created from the processed test dictionaries.\n",
        "\n",
        "# --- Filter and Prepare Data ---\n",
        "# Filters out rows where the 'Item' column contains the string \"SAME\".\n",
        "# These rows typically represent duplicate or skipped tests and are not needed for final analysis.\n",
        "data = data[~data['Item'].str.contains(\"SAME\", na=False)] # Filters out tests marked as 'SAME'.\n",
        "\n",
        "# Creates a new column 'Test name' by concatenating 'Item', 'Bias 1 Label', and 'Units'.\n",
        "# This provides a more descriptive name for each test.\n",
        "data['Test name'] = data['Item'] + \"@\" + data['Bias 1 Label'].astype(str) + data['Units'] # A descriptive name for each test, combining item, bias label, and units.\n",
        "\n",
        "# --- Define Limits ---\n",
        "# Hardcoded limits for different bias types. In a real scenario, these would likely be loaded from a configuration file or database.\n",
        "# limites_pruebas: A dictionary defining the low and high limits for various bias tests, along with a descriptive name.\n",
        "limites_pruebas = {\n",
        "    \"Bias 1\": {\"low_limit\": 0.005, \"high_limit\": 0.020, \"name\": \"Bias@A\"},\n",
        "    \"Bias 2\": {\"low_limit\": 0.01, \"high_limit\": 0.015, \"name\": \"Bias@V\"}\n",
        "    # Add more limits and configurations if needed\n",
        "}\n",
        "\n",
        "# --- Function to calculate group statistics ---\n",
        "def calculate_group_stats(bias_values, low_limit, high_limit):\n",
        "    \"\"\"\n",
        "    Calculates statistical metrics for a group of 'Bias 1' values.\n",
        "    Args:\n",
        "        bias_values (pd.Series): Series of 'Bias 1' values for a specific group.\n",
        "        low_limit (float): The lower specification limit.\n",
        "        high_limit (float): The upper specification limit.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing calculated statistics (Mean, Stdev, P50, Cp, Cpk, etc.).\n",
        "    \"\"\"\n",
        "    # Convert to numeric, coercing errors to NaN\n",
        "    numeric_bias_values = pd.to_numeric(bias_values, errors='coerce').dropna()\n",
        "\n",
        "    result_count = len(numeric_bias_values)\n",
        "\n",
        "    if result_count == 0:\n",
        "        # No valid data points, return default values\n",
        "        return {\n",
        "            \"P50\": 0.0,\n",
        "            \"Mean\": 0.0,\n",
        "            \"Stdev\": 0.0,\n",
        "            \"Cp\": 0.0,\n",
        "            \"Cpk\": 0.0,\n",
        "            \"Result count\": 0,\n",
        "            \"Fail count\": 0,\n",
        "            \"Yield (%)\": 0.0\n",
        "        }\n",
        "\n",
        "    mean_value = numeric_bias_values.mean()\n",
        "    stdev = numeric_bias_values.std() if result_count > 1 else 0.0 # Stdev is 0 for a single data point\n",
        "    p50 = numeric_bias_values.median()\n",
        "\n",
        "    # Calculate Fail count\n",
        "    fail_count = ((numeric_bias_values < low_limit) | (numeric_bias_values > high_limit)).sum()\n",
        "\n",
        "    # Calculate Cp and Cpk, handling division by zero\n",
        "    if stdev != 0:\n",
        "        cp = (high_limit - low_limit) / (6 * stdev)\n",
        "        cpk = min((high_limit - mean_value) / (3 * stdev), (mean_value - low_limit) / (3 * stdev))\n",
        "    else:\n",
        "        # If stdev is 0, process is perfectly centered or all values are identical.\n",
        "        # If all values are within limits, Cp/Cpk can be considered infinite/very high.\n",
        "        # If any value is outside limits, Cp/Cpk is 0 (or very bad).\n",
        "        if (numeric_bias_values >= low_limit).all() and (numeric_bias_values <= high_limit).all():\n",
        "            cp = np.inf # Or a very large number if np.inf causes issues downstream\n",
        "            cpk = np.inf # Or a very large number\n",
        "        else:\n",
        "            cp = 0.0\n",
        "            cpk = 0.0\n",
        "\n",
        "    # Calculate Yield (%)\n",
        "    yield_percent = ((result_count - fail_count) / result_count) * 100\n",
        "\n",
        "    return {\n",
        "        \"P50\": round(p50, 4),\n",
        "        \"Mean\": round(mean_value, 4),\n",
        "        \"Stdev\": round(stdev, 4),\n",
        "        \"Cp\": round(cp, 3),\n",
        "        \"Cpk\": round(cpk, 3),\n",
        "        \"Result count\": result_count,\n",
        "        \"Fail count\": fail_count,\n",
        "        \"Yield (%)\": round(yield_percent, 2)\n",
        "    }\n",
        "\n",
        "# --- Apply Grouped Statistics ---\n",
        "# Group the data by relevant attributes and apply the statistical calculation function.\n",
        "# We will also keep the first 'Test number' from each group for identification purposes.\n",
        "\n",
        "# Define grouping columns. 'Low limit' and 'High limit' are part of 'limites_pruebas' for 'Bias 1'.\n",
        "group_cols = ['Test name', 'Unit', 'Soft Bin']\n",
        "\n",
        "# Apply the function to each group\n",
        "aggregated_stats = data.groupby(group_cols).apply(lambda x: calculate_group_stats(\n",
        "    x['Bias 1'],\n",
        "    limites_pruebas[\"Bias 1\"][\"low_limit\"],\n",
        "    limites_pruebas[\"Bias 1\"][\"high_limit\"]\n",
        ")).reset_index()\n",
        "\n",
        "# The apply function returns a Series of dictionaries. We need to expand this into columns.\n",
        "# Create a DataFrame from the aggregated statistics dictionaries\n",
        "aggregated_stats_df = pd.json_normalize(aggregated_stats[0])\n",
        "\n",
        "# Combine the grouping columns with the new statistics columns\n",
        "tabla_final = pd.concat([aggregated_stats[group_cols], aggregated_stats_df], axis=1)\n",
        "\n",
        "# Add Low limit and High limit columns back, as they are fixed per test type from limites_pruebas\n",
        "tabla_final['Low limit'] = limites_pruebas[\"Bias 1\"][\"low_limit\"]\n",
        "tabla_final['High limit'] = limites_pruebas[\"Bias 1\"][\"high_limit\"]\n",
        "\n",
        "# Reorder columns to match the original output structure\n",
        "tabla_final = tabla_final[[\n",
        "    'Test name', 'Unit', 'Soft Bin', 'Low limit', 'High limit',\n",
        "    'P50', 'Mean', 'Stdev', 'Cp', 'Cpk', 'Result count', 'Fail count', 'Yield (%)'\n",
        "]]\n",
        "\n",
        "# For 'Test number', we can either drop it as it might not be relevant for grouped stats,\n",
        "# or take the minimum/maximum/first of the group. For now, it's not included in the grouped output directly.\n",
        "# If a 'Test number' is required, an additional step to merge it from the original 'data' based on group_cols would be needed.\n",
        "# As per the instruction, we're focusing on grouping by 'Test name', 'Unit', 'Soft Bin'.\n",
        "\n",
        "# Guardar tabla consolidada al CSV\n",
        "tabla_final.to_csv(\"Resultados_Modificados_ZDT_PGlobal.csv\", index=False)\n",
        "\n",
        "# Mostrar tabla final simulada\n",
        "print(tabla_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "978b1b25"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed with a `KeyError: 'Unit'` because the column in the `data` DataFrame is named `Units` (plural) not `Unit` (singular). I need to correct the column name in the `group_cols` list and in the final column reordering to match the actual DataFrame column name.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d91cb233"
      },
      "source": [
        "# This script processes raw test data from a CSV file, extracts key attributes, calculates statistical metrics for each test,\n",
        "# and consolidates the results into a final DataFrame for analysis and reporting.\n",
        "\n",
        "# --- Import Libraries ---\n",
        "# Import necessary libraries for data manipulation and numerical operations.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Load Data ---\n",
        "# Define the input CSV file name and load the data into a Pandas DataFrame.\n",
        "# The file is expected to contain metadata in the first 15 rows, which are skipped.\n",
        "# The separator is explicitly set to a comma.\n",
        "archivo_real = \"BZDT#115 Mainframe 815_(AGO.30.2024)DTA.CSV\"  # Specifies the name of the input CSV file containing raw test data.\n",
        "raw_df = pd.read_csv(archivo_real, skiprows=15, sep=',') # DataFrame holding the raw data read from the CSV, skipping initial metadata rows.\n",
        "\n",
        "# --- Identify Test Columns ---\n",
        "# Identifies columns that represent individual test numbers by checking if their names are purely numeric.\n",
        "# This ensures that only actual test data columns are considered for processing.\n",
        "test_columns = [col for col in raw_df.columns if str(col).isdigit()]\n",
        "\n",
        "# processed_data_list: An empty list to store dictionaries, each representing a processed test with its attributes and values.\n",
        "processed_data_list = []\n",
        "\n",
        "# --- Extract Attribute Rows ---\n",
        "# These lines extract specific rows from the raw_df that contain meta-information for each test.\n",
        "# They are identified by unique values in the 'Test' column (e.g., 'Item', 'Limit Units').\n",
        "# .iloc[0] is used to get the first (and expected only) matching row.\n",
        "# If a row is not found, an empty Series is created to prevent errors.\n",
        "item_row = raw_df[raw_df['Test'] == 'Item'].iloc[0] if not raw_df[raw_df['Test'] == 'Item'].empty else pd.Series(dtype=object) # Series containing 'Item' labels for each test.\n",
        "limit_units_row = raw_df[raw_df['Test'] == 'Limit Units'].iloc[0] if not raw_df[raw_df['Test'] == 'Limit Units'].empty else pd.Series(dtype=object) # Series containing 'Limit Units' for each test.\n",
        "bias1_value_row = raw_df[raw_df['Test'] == 'Bias 1 Value'].iloc[0] if not raw_df[raw_df['Test'] == 'Bias 1 Value'].empty else pd.Series(dtype=object) # Series containing 'Bias 1 Value' for each test.\n",
        "bias1_label_row = raw_df[raw_df['Test'] == 'Bias 1 Unit'].iloc[0] if not raw_df[raw_df['Test'] == 'Bias 1 Unit'].empty else pd.Series(dtype=object) # Series containing 'Bias 1 Unit' labels for each test.\n",
        "\n",
        "# Check for 'Bin' row. If it exists, extract it. Otherwise, create a dummy one.\n",
        "# The 'Bin' row indicates classification bins for tests, if available.\n",
        "bin_row_exists = raw_df['Test'].astype(str).str.contains('Bin', na=False).any() # Boolean flag indicating if a 'Bin' row exists in the raw data.\n",
        "if bin_row_exists:\n",
        "    bin_row = raw_df[raw_df['Test'].astype(str).str.contains('Bin', na=False)].iloc[0] # Series containing 'Bin' information for each test, if present.\n",
        "else:\n",
        "    bin_row = pd.Series(index=raw_df.columns, dtype=object) # Dummy Series created if no 'Bin' row is found.\n",
        "    for col in test_columns:\n",
        "        bin_row[col] = np.nan # Fills 'Bin' values with NaN for each test column if no 'Bin' row exists.\n",
        "\n",
        "# --- Process Test Data ---\n",
        "# Iterates through each identified test column to consolidate its attributes into a dictionary.\n",
        "# Each dictionary is then appended to `processed_data_list`.\n",
        "for col_name in test_columns:\n",
        "    # test_dict: A dictionary to hold attributes for the current test number.\n",
        "    test_dict = {\n",
        "        \"Test number\": int(col_name), # The numerical identifier for the test.\n",
        "        \"Item\": item_row.get(col_name, np.nan), # The 'Item' (name) of the test.\n",
        "        \"Bias 1 Label\": bias1_label_row.get(col_name, np.nan), # The label associated with 'Bias 1' (e.g., 'VSG').\n",
        "        \"Bias 1\": pd.to_numeric(bias1_value_row.get(col_name, np.nan), errors='coerce'), # The numerical value of 'Bias 1', converted to numeric.\n",
        "        \"Units\": limit_units_row.get(col_name, np.nan), # The units for the test limits.\n",
        "        \"Bin\": bin_row.get(col_name, np.nan) # The bin classification for the test.\n",
        "    }\n",
        "    processed_data_list.append(test_dict)\n",
        "\n",
        "# Convert the list of dictionaries into the main DataFrame 'data'.\n",
        "data = pd.DataFrame(processed_data_list) # DataFrame created from the processed test dictionaries.\n",
        "\n",
        "# --- Filter and Prepare Data ---\n",
        "# Filters out rows where the 'Item' column contains the string \"SAME\".\n",
        "# These rows typically represent duplicate or skipped tests and are not needed for final analysis.\n",
        "data = data[~data['Item'].str.contains(\"SAME\", na=False)] # Filters out tests marked as 'SAME'.\n",
        "\n",
        "# Creates a new column 'Test name' by concatenating 'Item', 'Bias 1 Label', and 'Units'.\n",
        "# This provides a more descriptive name for each test.\n",
        "data['Test name'] = data['Item'] + \"@\" + data['Bias 1 Label'].astype(str) + data['Units'] # A descriptive name for each test, combining item, bias label, and units.\n",
        "\n",
        "# --- Define Limits ---\n",
        "# Hardcoded limits for different bias types. In a real scenario, these would likely be loaded from a configuration file or database.\n",
        "# limites_pruebas: A dictionary defining the low and high limits for various bias tests, along with a descriptive name.\n",
        "limites_pruebas = {\n",
        "    \"Bias 1\": {\"low_limit\": 0.005, \"high_limit\": 0.020, \"name\": \"Bias@A\"},\n",
        "    \"Bias 2\": {\"low_limit\": 0.01, \"high_limit\": 0.015, \"name\": \"Bias@V\"}\n",
        "    # Add more limits and configurations if needed\n",
        "}\n",
        "\n",
        "# --- Function to calculate group statistics ---\n",
        "def calculate_group_stats(bias_values, low_limit, high_limit):\n",
        "    \"\"\"\n",
        "    Calculates statistical metrics for a group of 'Bias 1' values.\n",
        "    Args:\n",
        "        bias_values (pd.Series): Series of 'Bias 1' values for a specific group.\n",
        "        low_limit (float): The lower specification limit.\n",
        "        high_limit (float): The upper specification limit.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing calculated statistics (Mean, Stdev, P50, Cp, Cpk, etc.).\n",
        "    \"\"\"\n",
        "    # Convert to numeric, coercing errors to NaN\n",
        "    numeric_bias_values = pd.to_numeric(bias_values, errors='coerce').dropna()\n",
        "\n",
        "    result_count = len(numeric_bias_values)\n",
        "\n",
        "    if result_count == 0:\n",
        "        # No valid data points, return default values\n",
        "        return {\n",
        "            \"P50\": 0.0,\n",
        "            \"Mean\": 0.0,\n",
        "            \"Stdev\": 0.0,\n",
        "            \"Cp\": 0.0,\n",
        "            \"Cpk\": 0.0,\n",
        "            \"Result count\": 0,\n",
        "            \"Fail count\": 0,\n",
        "            \"Yield (%)\": 0.0\n",
        "        }\n",
        "\n",
        "    mean_value = numeric_bias_values.mean()\n",
        "    stdev = numeric_bias_values.std() if result_count > 1 else 0.0 # Stdev is 0 for a single data point\n",
        "    p50 = numeric_bias_values.median()\n",
        "\n",
        "    # Calculate Fail count\n",
        "    fail_count = ((numeric_bias_values < low_limit) | (numeric_bias_values > high_limit)).sum()\n",
        "\n",
        "    # Calculate Cp and Cpk, handling division by zero\n",
        "    if stdev != 0:\n",
        "        cp = (high_limit - low_limit) / (6 * stdev)\n",
        "        cpk = min((high_limit - mean_value) / (3 * stdev), (mean_value - low_limit) / (3 * stdev))\n",
        "    else:\n",
        "        # If stdev is 0, process is perfectly centered or all values are identical.\n",
        "        # If all values are within limits, Cp/Cpk can be considered infinite/very high.\n",
        "        # If any value is outside limits, Cp/Cpk is 0 (or very bad).\n",
        "        if (numeric_bias_values >= low_limit).all() and (numeric_bias_values <= high_limit).all():\n",
        "            cp = np.inf # Or a very large number if np.inf causes issues downstream\n",
        "            cpk = np.inf # Or a very large number\n",
        "        else:\n",
        "            cp = 0.0\n",
        "            cpk = 0.0\n",
        "\n",
        "    # Calculate Yield (%)\n",
        "    yield_percent = ((result_count - fail_count) / result_count) * 100\n",
        "\n",
        "    return {\n",
        "        \"P50\": round(p50, 4),\n",
        "        \"Mean\": round(mean_value, 4),\n",
        "        \"Stdev\": round(stdev, 4),\n",
        "        \"Cp\": round(cp, 3),\n",
        "        \"Cpk\": round(cpk, 3),\n",
        "        \"Result count\": result_count,\n",
        "        \"Fail count\": fail_count,\n",
        "        \"Yield (%)\": round(yield_percent, 2)\n",
        "    }\n",
        "\n",
        "# --- Apply Grouped Statistics ---\n",
        "# Group the data by relevant attributes and apply the statistical calculation function.\n",
        "\n",
        "# Define grouping columns. 'Low limit' and 'High limit' are part of 'limites_pruebas' for 'Bias 1'.\n",
        "group_cols = ['Test name', 'Units', 'Soft Bin'] # Corrected 'Unit' to 'Units'\n",
        "\n",
        "# Apply the function to each group\n",
        "aggregated_stats = data.groupby(group_cols, dropna=False).apply(lambda x: calculate_group_stats(\n",
        "    x['Bias 1'],\n",
        "    limites_pruebas[\"Bias 1\"][\"low_limit\"],\n",
        "    limites_pruebas[\"Bias 1\"][\"high_limit\"]\n",
        ")).reset_index()\n",
        "\n",
        "# The apply function returns a Series of dictionaries. We need to expand this into columns.\n",
        "# Create a DataFrame from the aggregated statistics dictionaries\n",
        "aggregated_stats_df = pd.json_normalize(aggregated_stats[0])\n",
        "\n",
        "# Combine the grouping columns with the new statistics columns\n",
        "tabla_final = pd.concat([aggregated_stats[group_cols], aggregated_stats_df], axis=1)\n",
        "\n",
        "# Add Low limit and High limit columns back, as they are fixed per test type from limites_pruebas\n",
        "tabla_final['Low limit'] = limites_pruebas[\"Bias 1\"][\"low_limit\"]\n",
        "tabla_final['High limit'] = limites_pruebas[\"Bias 1\"][\"high_limit\"]\n",
        "\n",
        "# Reorder columns to match the original output structure\n",
        "tabla_final = tabla_final[[\n",
        "    'Test name', 'Units', 'Soft Bin', 'Low limit', 'High limit',\n",
        "    'P50', 'Mean', 'Stdev', 'Cp', 'Cpk', 'Result count', 'Fail count', 'Yield (%)'\n",
        "]]\n",
        "\n",
        "# For 'Test number', it is not directly included in this grouped output as per the instructions focusing on grouping by 'Test name', 'Units', 'Soft Bin'.\n",
        "\n",
        "# Guardar tabla consolidada al CSV\n",
        "tabla_final.to_csv(\"Resultados_Modificados_ZDT_PGlobal.csv\", index=False)\n",
        "\n",
        "# Mostrar tabla final simulada\n",
        "print(tabla_final)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}